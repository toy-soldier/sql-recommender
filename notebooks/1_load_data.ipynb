{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042f1caf",
   "metadata": {},
   "source": [
    "# Notebook 1 – Data Loading\n",
    "\n",
    "This notebook handles the initial step of the workflow — loading raw CSV files into the database.  \n",
    "It takes the data stored in `data/*.csv` and writes each file to its corresponding table, establishing the foundation for all subsequent cleaning and analysis.\n",
    "\n",
    "The goal here is accuracy and traceability: every record is loaded as-is, without transformation, so that the raw source data remains a reliable point of reference for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9173fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necesary lbraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d536467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "DB_SERVER = os.getenv(\"DB_SERVER\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e90429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized engine at postgresql://postgres:***@localhost:5432/fundamentals\n"
     ]
    }
   ],
   "source": [
    "# initialize an SQLAlchemy engine for connecting to the database\n",
    "conn_string = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_SERVER}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "print(f\"Initialized engine at {db.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a271c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 records inserted into `companies` from ../data/companies.csv\n",
      "152 records inserted into `financials` from ../data/financials.csv\n",
      "36 records inserted into `industry_benchmarks` from ../data/industry_benchmarks.csv\n"
     ]
    }
   ],
   "source": [
    "# write the data in the CSVs to the database\n",
    "for name in [\"companies\", \"financials\", \"industry_benchmarks\"]:\n",
    "    path = f\"../data/{name}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.lower()  # to sanitize column names\n",
    "    recs = df.to_sql(name, db, if_exists=\"append\", index=False)\n",
    "    print(f\"{recs} records inserted into `{name}` from {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
